<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://nitish-nagesh.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://nitish-nagesh.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-10-13T20:46:40+00:00</updated><id>https://nitish-nagesh.github.io/feed.xml</id><title type="html">blank</title><subtitle>Nitish Nagesh - Ph.D. Candidate in Computer Science at UC Irvine. Research in causal inference, synthetic data generation, and fairness for health and medicine applications. </subtitle><entry><title type="html">Building Trustworthy AI for Health Applications</title><link href="https://nitish-nagesh.github.io/blog/2025/building-trustworthy-ai-for-health/" rel="alternate" type="text/html" title="Building Trustworthy AI for Health Applications"/><published>2025-01-15T00:00:00+00:00</published><updated>2025-01-15T00:00:00+00:00</updated><id>https://nitish-nagesh.github.io/blog/2025/building-trustworthy-ai-for-health</id><content type="html" xml:base="https://nitish-nagesh.github.io/blog/2025/building-trustworthy-ai-for-health/"><![CDATA[<p>As a Ph.D. candidate specializing in trustworthy AI for health applications, I’ve witnessed firsthand the transformative potential of artificial intelligence in healthcare. However, with great power comes great responsibility—especially when dealing with sensitive health data and life-critical decisions.</p> <h2 id="the-trust-challenge-in-healthcare-ai">The Trust Challenge in Healthcare AI</h2> <p>Healthcare AI systems face unique challenges that go beyond traditional machine learning applications:</p> <ul> <li><strong>Bias amplification</strong>: Historical healthcare disparities can be perpetuated by AI systems</li> <li><strong>Explainability requirements</strong>: Clinicians need to understand AI recommendations</li> <li><strong>Causal reasoning</strong>: Correlation doesn’t imply causation, especially in health outcomes</li> <li><strong>Fairness across populations</strong>: Ensuring equitable outcomes across diverse patient groups</li> </ul> <h2 id="my-research-approach-causal-fairness">My Research Approach: Causal Fairness</h2> <p>In my recent work on <strong>FairCauseSyn</strong>, we developed a framework for generating causally fair synthetic data using large language models. This approach addresses a critical gap in healthcare AI: how do we create training data that doesn’t perpetuate existing biases?</p> <h3 id="key-insights">Key Insights:</h3> <ol> <li><strong>Causal graphs matter</strong>: Understanding the causal relationships between variables is crucial for fair AI</li> <li><strong>Synthetic data can help</strong>: When real data is biased, carefully generated synthetic data can provide fairer training sets</li> <li><strong>LLMs as data generators</strong>: Large language models can be fine-tuned to generate causally consistent synthetic data</li> </ol> <h2 id="practical-applications">Practical Applications</h2> <p>This research has direct implications for:</p> <ul> <li><strong>Clinical decision support systems</strong></li> <li><strong>Drug discovery and development</strong></li> <li><strong>Personalized treatment recommendations</strong></li> <li><strong>Health outcome predictions</strong></li> </ul> <h2 id="looking-forward">Looking Forward</h2> <p>The future of healthcare AI lies in systems that are not just accurate, but also fair, explainable, and causally sound. As we continue to develop these technologies, it’s crucial that we prioritize patient safety and equity.</p> <hr/> <p><em>This post is part of my ongoing research on trustworthy AI for health applications. For more insights, follow my work on <a href="https://github.com/nitish-nagesh">GitHub</a> and connect with me on <a href="https://www.linkedin.com/in/nitish-nagesh/">LinkedIn</a>.</em></p> <p><strong>LinkedIn Cross-Post</strong>: This article was also published on <a href="https://www.linkedin.com/in/nitish-nagesh/">LinkedIn</a> for broader professional engagement. Feel free to share your thoughts and experiences with healthcare AI in the comments!</p>]]></content><author><name>Nitish Nagesh</name></author><category term="research"/><category term="AI"/><category term="health"/><category term="causal-inference"/><category term="fairness"/><category term="research"/><summary type="html"><![CDATA[Exploring the challenges and opportunities in developing fair, explainable AI systems for healthcare, with insights from my research on causal inference and bias mitigation.]]></summary></entry></feed>